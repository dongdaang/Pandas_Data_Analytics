{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측하려는 대상의 속성(설명 변수)을 입력 받고, 목표 변수가 갖고 있는 카테고리(범주형) 값 중에서 어느 한 값으로 분류하여 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k - Nearest - Neighbors\n",
    "#### 새로운 관측값이 주어지면, 기존 데이터 중에서 가장 속성이 비슷한 k개의 이웃을 먼저 찾음\n",
    "#### 그리고 가까운 이웃들이 갖고 있는 목표 값과 같은 값으로 분류하여 예측\n",
    "#### k값에 따라 예측의 정확도가 달라지므로, 적절한 k값을 찾는 것이 매우 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived' 'pclass' 'sex' 'age' 'sibsp' 'parch' 'fare' 'embarked' 'class'\n",
      " 'who' 'adult_male' 'alive' 'alone']\n"
     ]
    }
   ],
   "source": [
    "# NaN값이 많은 deck 열을 삭제, embarked와 내용이 겹치는 embark_town 열을 삭제\n",
    "rdf = df.drop(['deck', 'embark_town'], axis=1)  \n",
    "print(rdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
    "rdf = rdf.dropna(subset=['age'], how='any', axis=0)  \n",
    "print(len(rdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\n"
     ]
    }
   ],
   "source": [
    "# embarked 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()   \n",
    "print(most_freq)\n",
    "rdf['embarked'].fillna(most_freq, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - 속성 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch embarked\n",
      "0         0       3    male  22.0      1      0        S\n",
      "1         1       1  female  38.0      1      0        C\n",
      "2         1       3  female  26.0      0      0        S\n",
      "3         1       1  female  35.0      1      0        S\n",
      "4         0       3    male  35.0      0      0        S\n"
     ]
    }
   ],
   "source": [
    "# 분석에 활용할 열(속성)을 선택 \n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]    #survived는 예측 변수, 나머지는 설명 변수\n",
    "print(ndf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass   age  sibsp  parch  female  male  town_C  town_Q  town_S\n",
      "0         0       3  22.0      1      0       0     1       0       0       1\n",
      "1         1       1  38.0      1      0       1     0       1       0       0\n",
      "2         1       3  26.0      0      0       1     0       0       0       1\n",
      "3         1       1  35.0      1      0       1     0       0       0       1\n",
      "4         0       3  35.0      0      0       0     1       0       0       1\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis=1)    #concat() 메소드로 생성된 더미 변수 열을 기존 데이터프레임에 연결\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')    #prefix 옵션을 활용해 열 이름에 접두어를 붙임\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "print(ndf.head())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - 훈련 / 검증 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수:  (499, 9)\n",
      "test data 개수:  (215, 9)\n"
     ]
    }
   ],
   "source": [
    "# 속성(변수) 선택\n",
    "X=ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male', \n",
    "       'town_C', 'town_Q', 'town_S']]  #독립 변수 X\n",
    "y=ndf['survived']                      #종속 변수 Y\n",
    "\n",
    "# 설명 변수 데이터를 정규화(normalization) -> 데이터들끼리의 상대적 크기를 맞춰주기 위한 과정\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - 모형 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 1 1 0 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# sklearn 라이브러리에서 KNN 분류 모형 가져오기\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 모형 객체 생성 (k=5로 설정)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "knn.fit(X_train, y_train)   \n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류) \n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109  16]\n",
      " [ 25  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       125\n",
      "           1       0.80      0.72      0.76        90\n",
      "\n",
      "    accuracy                           0.81       215\n",
      "   macro avg       0.81      0.80      0.80       215\n",
      "weighted avg       0.81      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "#(0, 0) : TP(실제 : T, 예측 : T)\n",
    "#(0, 1) : FP(실제 : F, 예측 : T)\n",
    "#(1, 0) : FN(실제 : T, 예측 : F)\n",
    "#(1, 1) : TN(실제 : F, 예측 : F)\n",
    "from sklearn import metrics \n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
    "print(knn_matrix)\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "#f1-score : 각각의 케이스에 대한 예측 정확도\n",
    "knn_report = metrics.classification_report(y_test, y_hat)            \n",
    "print(knn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine\n",
    "#### 벡터 공간에 위치한 훈련 데이터의 좌표와 각 데이터가 어떤 분류 값을 가져야 하는지 정답을 입력 받아서 학습\n",
    "#### 같은 분류 값을 갖는 데이터끼리 같은 공간에 위치하도록 벡터 공간을 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비\n",
    "#### 이전 데이터와 동일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 0 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# sklearn 라이브러리에서 SVM 분류 모형 가져오기\n",
    "from sklearn import svm\n",
    "\n",
    "# 모형 객체 생성 (kernel='rbf' 적용)\n",
    "#kernel 함수 -> 데이터를 벡터 공간으로 매핑하는 메소드(여기서는 rbf함수 적용)\n",
    "svm_model = svm.SVC(kernel='rbf')\n",
    "\n",
    "svm_model.fit(X_train, y_train)   \n",
    "\n",
    "y_hat = svm_model.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120   5]\n",
      " [ 35  55]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86       125\n",
      "           1       0.92      0.61      0.73        90\n",
      "\n",
      "    accuracy                           0.81       215\n",
      "   macro avg       0.85      0.79      0.80       215\n",
      "weighted avg       0.83      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
    "print(svm_matrix)\n",
    "print('\\n')\n",
    "\n",
    "svm_report = metrics.classification_report(y_test, y_hat)            \n",
    "print(svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 node에 분석 대상의 속성(설명 변수)들이 위치\n",
    "#### 각 node마다 목표 값을 가장 잘 분류할 수 있는 속성을 찾아 배치, 해당 속성이 갖는 값을 이용하여 새로운 branch를 만듦\n",
    "#### 각 node에 최적의 속성을 선택할 때는, 해당 속성을 기준으로 분류한 값들이 구분되는 정도를 측정\n",
    "#### Entropy -> 다른 종류의 값들이 섞여 있는 정도, 낮을수록 분류가 잘 된 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  clump  cell_size  cell_shape  adhesion  epithlial bare_nuclei  \\\n",
      "0  1000025      5          1           1         1          2           1   \n",
      "1  1002945      5          4           4         5          7          10   \n",
      "2  1015425      3          1           1         1          2           2   \n",
      "3  1016277      6          8           8         1          3           4   \n",
      "4  1017023      4          1           1         3          2           1   \n",
      "\n",
      "   chromatin  normal_nucleoli  mitoses  class  \n",
      "0          3                1        1      2  \n",
      "1          3                2        1      2  \n",
      "2          3                1        1      2  \n",
      "3          3                7        1      2  \n",
      "4          3                1        1      2  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               699 non-null    int64 \n",
      " 1   clump            699 non-null    int64 \n",
      " 2   cell_size        699 non-null    int64 \n",
      " 3   cell_shape       699 non-null    int64 \n",
      " 4   adhesion         699 non-null    int64 \n",
      " 5   epithlial        699 non-null    int64 \n",
      " 6   bare_nuclei      699 non-null    object\n",
      " 7   chromatin        699 non-null    int64 \n",
      " 8   normal_nucleoli  699 non-null    int64 \n",
      " 9   mitoses          699 non-null    int64 \n",
      " 10  class            699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "                 id       clump   cell_size  cell_shape    adhesion  \\\n",
      "count  6.990000e+02  699.000000  699.000000  699.000000  699.000000   \n",
      "mean   1.071704e+06    4.417740    3.134478    3.207439    2.806867   \n",
      "std    6.170957e+05    2.815741    3.051459    2.971913    2.855379   \n",
      "min    6.163400e+04    1.000000    1.000000    1.000000    1.000000   \n",
      "25%    8.706885e+05    2.000000    1.000000    1.000000    1.000000   \n",
      "50%    1.171710e+06    4.000000    1.000000    1.000000    1.000000   \n",
      "75%    1.238298e+06    6.000000    5.000000    5.000000    4.000000   \n",
      "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
      "\n",
      "        epithlial   chromatin  normal_nucleoli     mitoses       class  \n",
      "count  699.000000  699.000000       699.000000  699.000000  699.000000  \n",
      "mean     3.216023    3.437768         2.866953    1.589413    2.689557  \n",
      "std      2.214300    2.438364         3.053634    1.715078    0.951273  \n",
      "min      1.000000    1.000000         1.000000    1.000000    2.000000  \n",
      "25%      2.000000    2.000000         1.000000    1.000000    2.000000  \n",
      "50%      2.000000    3.000000         1.000000    1.000000    2.000000  \n",
      "75%      4.000000    5.000000         4.000000    1.000000    4.000000  \n",
      "max     10.000000   10.000000        10.000000   10.000000    4.000000  \n"
     ]
    }
   ],
   "source": [
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "df.columns = ['id', 'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "              'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1' '10' '2' '4' '3' '9' '7' '?' '5' '8' '6']\n",
      "\n",
      "\n",
      "                 id       clump   cell_size  cell_shape    adhesion  \\\n",
      "count  6.830000e+02  683.000000  683.000000  683.000000  683.000000   \n",
      "mean   1.076720e+06    4.442167    3.150805    3.215227    2.830161   \n",
      "std    6.206440e+05    2.820761    3.065145    2.988581    2.864562   \n",
      "min    6.337500e+04    1.000000    1.000000    1.000000    1.000000   \n",
      "25%    8.776170e+05    2.000000    1.000000    1.000000    1.000000   \n",
      "50%    1.171795e+06    4.000000    1.000000    1.000000    1.000000   \n",
      "75%    1.238705e+06    6.000000    5.000000    5.000000    4.000000   \n",
      "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
      "\n",
      "        epithlial  bare_nuclei   chromatin  normal_nucleoli     mitoses  \\\n",
      "count  683.000000   683.000000  683.000000       683.000000  683.000000   \n",
      "mean     3.234261     3.544656    3.445095         2.869693    1.603221   \n",
      "std      2.223085     3.643857    2.449697         3.052666    1.732674   \n",
      "min      1.000000     1.000000    1.000000         1.000000    1.000000   \n",
      "25%      2.000000     1.000000    2.000000         1.000000    1.000000   \n",
      "50%      2.000000     1.000000    3.000000         1.000000    1.000000   \n",
      "75%      4.000000     6.000000    5.000000         4.000000    1.000000   \n",
      "max     10.000000    10.000000   10.000000        10.000000   10.000000   \n",
      "\n",
      "            class  \n",
      "count  683.000000  \n",
      "mean     2.699854  \n",
      "std      0.954592  \n",
      "min      2.000000  \n",
      "25%      2.000000  \n",
      "50%      2.000000  \n",
      "75%      4.000000  \n",
      "max      4.000000  \n"
     ]
    }
   ],
   "source": [
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "# bare_nuclei 열의 고유값 확인\n",
    "import numpy as np\n",
    "\n",
    "print(df['bare_nuclei'].unique())\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')       # 문자열을 정수형으로 변환\n",
    "\n",
    "print(df.describe())                                      # 데이터 통계 요약정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수:  (478, 9)\n",
      "test data 개수:  (205, 9)\n"
     ]
    }
   ],
   "source": [
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "        'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']]  # 설명 변수 X\n",
    "y = df['class']  # 예측 변수 Y\n",
    "\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모형 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n"
     ]
    }
   ],
   "source": [
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)    #5단계까지 가지를 확장할 수 있다는 뜻\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)      # 2: benign(양성), 4: malignant(악성)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127   4]\n",
      " [  2  72]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.98       131\n",
      "           4       0.95      0.97      0.96        74\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
